<!--
Licensed to the Apache Software Foundation (ASF) under one
or more contributor license agreements.  See the NOTICE file
distributed with this work for additional information
regarding copyright ownership.  The ASF licenses this file
to you under the Apache License, Version 2.0 (the
"License"); you may not use this file except in compliance
with the License.  You may obtain a copy of the License at

http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing,
software distributed under the License is distributed on an
"AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
KIND, either express or implied.  See the License for the
specific language governing permissions and limitations
under the License.
-->
<!DOCTYPE html>

<html lang="en">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <!-- The above 3 meta tags *must* come first in the head; any other head content must come *after* these tags -->
    <title>Apache Flink 1.2 Documentation: Hadoop Compatibility</title>
    <link rel="shortcut icon" href="/1.2.0/page/favicon.ico" type="image/x-icon">
    <link rel="icon" href="/1.2.0/page/favicon.ico" type="image/x-icon">

    <!-- Bootstrap -->
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.4/css/bootstrap.min.css">
    <link rel="stylesheet" href="/1.2.0/page/css/flink.css">
    <link rel="stylesheet" href="/1.2.0/page/css/syntax.css">
    <link rel="stylesheet" href="/1.2.0/page/css/codetabs.css">
    <link rel="stylesheet" href="/1.2.0/page/font-awesome/css/font-awesome.min.css">
    
    <!-- HTML5 shim and Respond.js for IE8 support of HTML5 elements and media queries -->
    <!-- WARNING: Respond.js doesn't work if you view the page via file:// -->
    <!--[if lt IE 9]>
      <script src="https://oss.maxcdn.com/html5shiv/3.7.2/html5shiv.min.js"></script>
      <script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
    <![endif]-->
  </head>
  <body>
    
    
    

    <!-- Main content. -->
    <div class="container">
      
      <div class="row">
        <div class="col-lg-3">
          







  
    
    
    
      
    
  

  
    
    
    
      
    
  

  
    
    
    
      









  





<div class="sidenav-logo">
  <p><a href="/1.2.0"><img class="bottom" alt="Apache Flink" src="/1.2.0/page/img/navbar-brand-logo.jpg"></a> v1.2</p>
</div>
<ul id="sidenav">

  
    

    
      
    

    
    
    

    

    
    
<li><a href="/1.2.0/index.html"><i class="fa fa-home title" aria-hidden="true"></i> 首页</a></li>
    
  

  
    

    
      
    

    
    
    

    <hr class="section-break"></hr>

    
    
      
      
        
        
<li><a href="#collapse-2" data-toggle="collapse"><i class="fa fa-map-o title appetizer" aria-hidden="true"></i> 概念 <i class="fa fa-caret-down pull-right" aria-hidden="true" style="padding-top: 4px"></i></a><div class="collapse" id="collapse-2"><ul>
  
        
        
        

        
        
      
    
  

  
    

    
      
    

    
    
    

    

    
    
      
      
<li><a href="/1.2.0/concepts/programming-model.html">编程模型</a></li>
      
    
  

  
    

    
      
    

    
    
    

    

    
    
<li><a href="/1.2.0/concepts/runtime.html">Distributed Runtime</a></li>
    
  

  
    
      
      
</li></ul></div>
      
      
    
  

  
    

    
      
    

    
    
    

    

    
    
<li><a href="/1.2.0/quickstart/setup_quickstart.html"><i class="fa fa-power-off title appetizer" aria-hidden="true"></i> 快速起步</a></li>
    
  

  
    

    
      
    

    
    
    

    

    
    
      
      
        
        
<li><a href="#collapse-7" data-toggle="collapse"><i class="fa fa-file-code-o title appetizer" aria-hidden="true"></i> 示例 <i class="fa fa-caret-down pull-right" aria-hidden="true" style="padding-top: 4px"></i></a><div class="collapse" id="collapse-7"><ul>
  <li><a href="/1.2.0/examples/index.html">Overview</a></li>
        
        
        

        
        
      
    
  

  
    

    
      
    

    
    
    

    

    
    
<li><a href="/1.2.0/quickstart/run_example_quickstart.html">Monitoring Wikipedia Edits</a></li>
    
  

  
    

    
      
    

    
    
    

    

    
    
<li><a href="/1.2.0/dev/batch/examples.html">Batch Examples</a></li>
    
  

  
    
      
      
</li></ul></div>
      
      
    
  

  
    

    
      
    

    
    
    

    <hr class="section-break"></hr>

    
    
      
      
        
        
<li><a href="#collapse-11" data-toggle="collapse"><i class="fa fa-cogs title maindish" aria-hidden="true"></i> 建立工程 <i class="fa fa-caret-down pull-right" aria-hidden="true" style="padding-top: 4px"></i></a><div class="collapse" id="collapse-11"><ul>
  
        
        
        

        
        
      
    
  

  
    

    
      
    

    
    
    

    

    
    
<li><a href="/1.2.0/quickstart/java_api_quickstart.html">Java 的样例工程</a></li>
    
  

  
    

    
      
    

    
    
    

    

    
    
<li><a href="/1.2.0/quickstart/scala_api_quickstart.html">Scala 的样例工程</a></li>
    
  

  
    

    
      
    

    
    
    

    

    
    
<li><a href="/1.2.0/dev/linking_with_flink.html">Linking with Flink</a></li>
    
  

  
    

    
      
    

    
    
    

    

    
    
<li><a href="/1.2.0/internals/ide_setup.html">IDE Setup</a></li>
    
  

  
    

    
      
    

    
    
    

    

    
    
<li><a href="/1.2.0/dev/scala_shell.html">Scala REPL</a></li>
    
  

  
    

    
      
    

    
    
    

    

    
    
<li><a href="/1.2.0/dev/linking.html">关联可选模块</a></li>
    
  

  
    

    
      
    

    
    
    

    

    
    
<li><a href="/1.2.0/setup/flink_on_windows.html">Running Flink on Windows</a></li>
    
  

  
    

    
      
    

    
    
    

    

    
    
<li><a href="/1.2.0/setup/building.html">Building Flink from Source</a></li>
    
  

  
    
      
      
</li></ul></div>
      
      
    
  

  
    

    
      
    

    
    
    

    

    
    
      
      
        
        
<li><a href="#collapse-21" data-toggle="collapse" class="active"><i class="fa fa-code title maindish" aria-hidden="true"></i> 应用开发</a><div class="collapse in" id="collapse-21"><ul>
  
        
        
        

        
        
      
    
  

  
    

    
      
    

    
    
    

    

    
    
      
      
        
        
<li><a href="#collapse-22" data-toggle="collapse">Basic API Concepts <i class="fa fa-caret-down pull-right" aria-hidden="true" style="padding-top: 4px"></i></a><div class="collapse" id="collapse-22"><ul>
  <li><a href="/1.2.0/dev/api_concepts.html">Overview</a></li>
        
        
        

        
        
      
    
  

  
    

    
      
    

    
    
    

    

    
    
<li><a href="/1.2.0/dev/scala_api_extensions.html">Scala API Extensions</a></li>
    
  

  
    

    
      
    

    
    
    

    

    
    
<li><a href="/1.2.0/dev/java8.html">Java 8</a></li>
    
  

  
    
      
      
</li></ul></div>
      
      
    
  

  
    

    
      
    

    
    
    

    

    
    
      
      
        
        
<li><a href="#collapse-26" data-toggle="collapse">Streaming (DataStream API) <i class="fa fa-caret-down pull-right" aria-hidden="true" style="padding-top: 4px"></i></a><div class="collapse" id="collapse-26"><ul>
  <li><a href="/1.2.0/dev/datastream_api.html">Overview</a></li>
        
        
        

        
        
      
    
  

  
    

    
      
    

    
    
    

    

    
    
      
      
<li><a href="/1.2.0/dev/windows.html">Windows</a></li>
      
    
  

  
    

    
      
    

    
    
    

    

    
    
      
      
        
        
<li><a href="#collapse-28" data-toggle="collapse">Event Time <i class="fa fa-caret-down pull-right" aria-hidden="true" style="padding-top: 4px"></i></a><div class="collapse" id="collapse-28"><ul>
  <li><a href="/1.2.0/dev/event_time.html">Overview</a></li>
        
        
        

        
        
      
    
  

  
    

    
      
    

    
    
    

    

    
    
<li><a href="/1.2.0/dev/event_timestamps_watermarks.html">Generating Timestamps / Watermarks</a></li>
    
  

  
    

    
      
    

    
    
    

    

    
    
<li><a href="/1.2.0/dev/event_timestamp_extractors.html">预定义的 Timestamp Extractors / Watermark Emitters</a></li>
    
  

  
    
      
      
</li></ul></div>
      
      
    
  

  
    

    
      
    

    
    
    

    

    
    
      
      
        
        
<li><a href="#collapse-32" data-toggle="collapse">Connectors <i class="fa fa-caret-down pull-right" aria-hidden="true" style="padding-top: 4px"></i></a><div class="collapse" id="collapse-32"><ul>
  <li><a href="/1.2.0/dev/connectors/index.html">Overview</a></li>
        
        
        

        
        
      
    
  

  
    

    
      
    

    
    
    

    

    
    
<li><a href="/1.2.0/dev/connectors/guarantees.html">Fault Tolerance Guarantees</a></li>
    
  

  
    

    
      
    

    
    
    

    

    
    
<li><a href="/1.2.0/dev/connectors/kafka.html">Kafka</a></li>
    
  

  
    

    
      
    

    
    
    

    

    
    
<li><a href="/1.2.0/dev/connectors/cassandra.html">Cassandra</a></li>
    
  

  
    

    
      
    

    
    
    

    

    
    
<li><a href="/1.2.0/dev/connectors/kinesis.html">Kinesis</a></li>
    
  

  
    

    
      
    

    
    
    

    

    
    
<li><a href="/1.2.0/dev/connectors/elasticsearch.html">Elasticsearch</a></li>
    
  

  
    

    
      
    

    
    
    

    

    
    
<li><a href="/1.2.0/dev/connectors/filesystem_sink.html">Rolling File Sink</a></li>
    
  

  
    

    
      
    

    
    
    

    

    
    
<li><a href="/1.2.0/dev/connectors/rabbitmq.html">RabbitMQ</a></li>
    
  

  
    

    
      
    

    
    
    

    

    
    
<li><a href="/1.2.0/dev/connectors/nifi.html">NiFi</a></li>
    
  

  
    

    
      
    

    
    
    

    

    
    
<li><a href="/1.2.0/dev/connectors/twitter.html">Twitter</a></li>
    
  

  
    
      
      
</li></ul></div>
      
      
    
  

  
    

    
      
    

    
    
    

    

    
    
<li><a href="/1.2.0/dev/stream/process_function.html">过程函数</a></li>
    
  

  
    

    
      
    

    
    
    

    

    
    
<li><a href="/1.2.0/dev/stream/side_output.html">Side Outputs</a></li>
    
  

  
    

    
      
    

    
    
    

    

    
    
<li><a href="/1.2.0/dev/stream/state.html">Working with State</a></li>
    
  

  
    

    
      
    

    
    
    

    

    
    
<li><a href="/1.2.0/dev/stream/checkpointing.html">Checkpointing</a></li>
    
  

  
    

    
      
    

    
    
    

    

    
    
<li><a href="/1.2.0/dev/stream/asyncio.html">Async I/O</a></li>
    
  

  
    

    
      
    

    
    
    

    

    
    
<li><a href="/1.2.0/dev/stream/queryable_state.html">Queryable State</a></li>
    
  

  
    
      
      
</li></ul></div>
      
      
    
  

  
    

    
      
    

    
    
    

    

    
    
      
      
        
        
<li><a href="#collapse-50" data-toggle="collapse" class="active">批 (DataSet API)</a><div class="collapse in" id="collapse-50"><ul>
  <li><a href="/1.2.0/dev/batch/index.html">Overview</a></li>
        
        
        

        
        
      
    
  

  
    

    
      
    

    
    
    

    

    
    
<li><a href="/1.2.0/dev/batch/dataset_transformations.html">Transformations</a></li>
    
  

  
    

    
      
    

    
    
    

    

    
    
<li><a href="/1.2.0/dev/batch/iterations.html">Iterations</a></li>
    
  

  
    

    
      
    

    
    
    

    

    
    
<li><a href="/1.2.0/dev/batch/zip_elements_guide.html">Zipping Elements</a></li>
    
  

  
    

    
      
    

    
    
    

    

    
    
<li><a href="/1.2.0/dev/batch/fault_tolerance.html">Fault Tolerance</a></li>
    
  

  
    

    
      
    

    
    
    

    

    
    
<li><a href="/1.2.0/dev/batch/python.html">Python API</a></li>
    
  

  
    

    
      
    

    
    
    

    

    
    
<li><a href="/1.2.0/dev/batch/connectors.html">Connectors</a></li>
    
  

  
    

    
      
    

    
    
    

    

    
    
<li><a href="/1.2.0/dev/batch/hadoop_compatibility.html" class="active">Hadoop Compatibility</a></li>
    
  

  
    

    
      
    

    
    
    

    

    
    
<li><a href="/1.2.0/dev/local_execution.html">Local Execution</a></li>
    
  

  
    

    
      
    

    
    
    

    

    
    
<li><a href="/1.2.0/dev/cluster_execution.html">Cluster Execution</a></li>
    
  

  
    
      
      
</li></ul></div>
      
      
    
  

  
    

    
      
    

    
    
    

    

    
    
      
      
        
        
<li><a href="#collapse-61" data-toggle="collapse">数据类型和序列化 <i class="fa fa-caret-down pull-right" aria-hidden="true" style="padding-top: 4px"></i></a><div class="collapse" id="collapse-61"><ul>
  <li><a href="/1.2.0/dev/types_serialization.html">Overview</a></li>
        
        
        

        
        
      
    
  

  
    

    
      
    

    
    
    

    

    
    
<li><a href="/1.2.0/dev/custom_serializers.html">Custom Serializers</a></li>
    
  

  
    
      
      
</li></ul></div>
      
      
    
  

  
    

    
      
    

    
    
    

    

    
    
      
      
        
        
<li><a href="#collapse-64" data-toggle="collapse">Managing Execution <i class="fa fa-caret-down pull-right" aria-hidden="true" style="padding-top: 4px"></i></a><div class="collapse" id="collapse-64"><ul>
  
        
        
        

        
        
      
    
  

  
    

    
      
    

    
    
    

    

    
    
<li><a href="/1.2.0/dev/execution_configuration.html">Execution Configuration</a></li>
    
  

  
    

    
      
    

    
    
    

    

    
    
<li><a href="/1.2.0/dev/packaging.html">Program Packaging</a></li>
    
  

  
    

    
      
    

    
    
    

    

    
    
<li><a href="/1.2.0/dev/parallel.html">并行执行</a></li>
    
  

  
    

    
      
    

    
    
    

    

    
    
<li><a href="/1.2.0/dev/execution_plans.html">执行计划</a></li>
    
  

  
    

    
      
    

    
    
    

    

    
    
<li><a href="/1.2.0/dev/restart_strategies.html">Restart Strategies</a></li>
    
  

  
    
      
      
</li></ul></div>
      
      
    
  

  
    

    
      
    

    
    
    

    

    
    
      
      
        
        
<li><a href="#collapse-71" data-toggle="collapse">Libraries <i class="fa fa-caret-down pull-right" aria-hidden="true" style="padding-top: 4px"></i></a><div class="collapse" id="collapse-71"><ul>
  
        
        
        

        
        
      
    
  

  
    

    
      
    

    
    
    

    

    
    
<li><a href="/1.2.0/dev/table_api.html">Table and SQL</a></li>
    
  

  
    

    
      
    

    
    
    

    

    
    
<li><a href="/1.2.0/dev/libs/cep.html">Event Processing (CEP)</a></li>
    
  

  
    

    
      
    

    
    
    

    

    
    
<li><a href="/1.2.0/dev/libs/storm_compatibility.html">Storm Compatibility</a></li>
    
  

  
    

    
      
    

    
    
    

    

    
    
      
      
        
        
<li><a href="#collapse-75" data-toggle="collapse">Graphs: Gelly <i class="fa fa-caret-down pull-right" aria-hidden="true" style="padding-top: 4px"></i></a><div class="collapse" id="collapse-75"><ul>
  <li><a href="/1.2.0/dev/libs/gelly/index.html">Overview</a></li>
        
        
        

        
        
      
    
  

  
    

    
      
    

    
    
    

    

    
    
<li><a href="/1.2.0/dev/libs/gelly/graph_api.html">Graph API</a></li>
    
  

  
    

    
      
    

    
    
    

    

    
    
<li><a href="/1.2.0/dev/libs/gelly/iterative_graph_processing.html">Iterative Graph Processing</a></li>
    
  

  
    

    
      
    

    
    
    

    

    
    
<li><a href="/1.2.0/dev/libs/gelly/library_methods.html">Library Methods</a></li>
    
  

  
    

    
      
    

    
    
    

    

    
    
<li><a href="/1.2.0/dev/libs/gelly/graph_algorithms.html">Graph Algorithms</a></li>
    
  

  
    

    
      
    

    
    
    

    

    
    
<li><a href="/1.2.0/dev/libs/gelly/graph_generators.html">Graph Generators</a></li>
    
  

  
    

    
      
    

    
    
    

    

    
    
<li><a href="/1.2.0/dev/libs/gelly/bipartite_graph.html">Bipartite Graph</a></li>
    
  

  
    
      
      
</li></ul></div>
      
      
    
  

  
    

    
      
    

    
    
    

    

    
    
      
      
        
        
<li><a href="#collapse-83" data-toggle="collapse">机器学习 <i class="fa fa-caret-down pull-right" aria-hidden="true" style="padding-top: 4px"></i></a><div class="collapse" id="collapse-83"><ul>
  <li><a href="/1.2.0/dev/libs/ml/index.html">Overview</a></li>
        
        
        

        
        
      
    
  

  
    

    
      
    

    
    
    

    

    
    
<li><a href="/1.2.0/dev/libs/ml/quickstart.html">快速入门</a></li>
    
  

  
    

    
      
    

    
    
    

    

    
    
<li><a href="/1.2.0/dev/libs/ml/multiple_linear_regression.html">多元线性回归</a></li>
    
  

  
    

    
      
    

    
    
    

    

    
    
<li><a href="/1.2.0/dev/libs/ml/cross_validation.html">交叉验证</a></li>
    
  

  
    

    
      
    

    
    
    

    

    
    
<li><a href="/1.2.0/dev/libs/ml/distance_metrics.html">距离度量</a></li>
    
  

  
    

    
      
    

    
    
    

    

    
    
<li><a href="/1.2.0/dev/libs/ml/knn.html">K近邻算法（KNN）</a></li>
    
  

  
    

    
      
    

    
    
    

    

    
    
<li><a href="/1.2.0/dev/libs/ml/min_max_scaler.html">最小最大值标准化</a></li>
    
  

  
    

    
      
    

    
    
    

    

    
    
<li><a href="/1.2.0/dev/libs/ml/contribution_guide.html">贡献指南</a></li>
    
  

  
    

    
      
    

    
    
    

    

    
    
<li><a href="/1.2.0/dev/libs/ml/pipelines.html">Pipelines</a></li>
    
  

  
    

    
      
    

    
    
    

    

    
    
<li><a href="/1.2.0/dev/libs/ml/polynomial_features.html">多项式特征转换</a></li>
    
  

  
    

    
      
    

    
    
    

    

    
    
<li><a href="/1.2.0/dev/libs/ml/als.html">ALS</a></li>
    
  

  
    

    
      
    

    
    
    

    

    
    
<li><a href="/1.2.0/dev/libs/ml/sos.html">Stochastic Outlier Selection</a></li>
    
  

  
    

    
      
    

    
    
    

    

    
    
<li><a href="/1.2.0/dev/libs/ml/standard_scaler.html">标准化缩放</a></li>
    
  

  
    

    
      
    

    
    
    

    

    
    
<li><a href="/1.2.0/dev/libs/ml/svm.html">支持向量机（SVM using CoCoA）</a></li>
    
  

  
    
      
      
</li></ul></div>
      
      
    
  

  
    
      
      
</li></ul></div>
      
      
    
  

  
    

    
      
    

    
    
    

    

    
    
<li><a href="/1.2.0/dev/best_practices.html">Best Practices</a></li>
    
  

  
    

    
      
    

    
    
    

    

    
    
<li><a href="/1.2.0/dev/migration.html">API Migration Guides</a></li>
    
  

  
    
      
      
</li></ul></div>
      
      
    
  

  
    

    
      
    

    
    
    

    

    
    
      
      
        
        
<li><a href="#collapse-102" data-toggle="collapse"><i class="fa fa-sliders title maindish" aria-hidden="true"></i> 部署与运维 <i class="fa fa-caret-down pull-right" aria-hidden="true" style="padding-top: 4px"></i></a><div class="collapse" id="collapse-102"><ul>
  
        
        
        

        
        
      
    
  

  
    

    
      
    

    
    
    

    

    
    
      
      
<li><a href="/1.2.0/setup/config.html">Configuration</a></li>
      
    
  

  
    

    
      
    

    
    
    

    

    
    
<li><a href="/1.2.0/setup/cli.html">CLI</a></li>
    
  

  
    

    
      
    

    
    
    

    

    
    
      
      
        
        
<li><a href="#collapse-105" data-toggle="collapse">Clusters & Deployment <i class="fa fa-caret-down pull-right" aria-hidden="true" style="padding-top: 4px"></i></a><div class="collapse" id="collapse-105"><ul>
  
        
        
        

        
        
      
    
  

  
    

    
      
    

    
    
    

    

    
    
<li><a href="/1.2.0/setup/cluster_setup.html">Standalone Cluster</a></li>
    
  

  
    

    
      
    

    
    
    

    

    
    
<li><a href="/1.2.0/setup/yarn_setup.html">YARN</a></li>
    
  

  
    

    
      
    

    
    
    

    

    
    
<li><a href="/1.2.0/setup/mesos.html">Mesos</a></li>
    
  

  
    

    
      
    

    
    
    

    

    
    
<li><a href="/1.2.0/setup/aws.html">AWS</a></li>
    
  

  
    

    
      
    

    
    
    

    

    
    
<li><a href="/1.2.0/setup/gce_setup.html">Google Compute Engine</a></li>
    
  

  
    

    
      
    

    
    
    

    

    
    
<li><a href="/1.2.0/setup/mapr_setup.html">MapR</a></li>
    
  

  
    
      
      
</li></ul></div>
      
      
    
  

  
    

    
      
    

    
    
    

    

    
    
<li><a href="/1.2.0/setup/jobmanager_high_availability.html">High Availability (HA)</a></li>
    
  

  
    

    
      
    

    
    
    

    

    
    
<li><a href="/1.2.0/setup/checkpoints.html">Checkpoints</a></li>
    
  

  
    

    
      
    

    
    
    

    

    
    
<li><a href="/1.2.0/setup/savepoints.html">Savepoints</a></li>
    
  

  
    

    
      
    

    
    
    

    

    
    
<li><a href="/1.2.0/setup/security-ssl.html">SSL Setup</a></li>
    
  

  
    

    
      
    

    
    
    

    

    
    
<li><a href="/1.2.0/ops/security-kerberos.html">Kerberos</a></li>
    
  

  
    

    
      
    

    
    
    

    

    
    
<li><a href="/1.2.0/ops/upgrading.html">Upgrading Applications and Flink Versions</a></li>
    
  

  
    

    
      
    

    
    
    

    

    
    
<li><a href="/1.2.0/ops/production_ready.html">生产环境检查清单</a></li>
    
  

  
    
      
      
</li></ul></div>
      
      
    
  

  
    

    
      
    

    
    
    

    

    
    
      
      
        
        
<li><a href="#collapse-121" data-toggle="collapse"><i class="fa fa-bug title maindish" aria-hidden="true"></i> 调试与监控 <i class="fa fa-caret-down pull-right" aria-hidden="true" style="padding-top: 4px"></i></a><div class="collapse" id="collapse-121"><ul>
  
        
        
        

        
        
      
    
  

  
    

    
      
    

    
    
    

    

    
    
<li><a href="/1.2.0/monitoring/metrics.html">Metrics</a></li>
    
  

  
    

    
      
    

    
    
    

    

    
    
<li><a href="/1.2.0/monitoring/logging.html">Logging</a></li>
    
  

  
    

    
      
    

    
    
    

    

    
    
<li><a href="/1.2.0/monitoring/historyserver.html">History Server</a></li>
    
  

  
    

    
      
    

    
    
    

    

    
    
<li><a href="/1.2.0/monitoring/checkpoint_monitoring.html">Monitoring Checkpointing</a></li>
    
  

  
    

    
      
    

    
    
    

    

    
    
<li><a href="/1.2.0/monitoring/back_pressure.html">Monitoring Back Pressure</a></li>
    
  

  
    

    
      
    

    
    
    

    

    
    
<li><a href="/1.2.0/monitoring/rest_api.html">Monitoring REST API</a></li>
    
  

  
    

    
      
    

    
    
    

    

    
    
<li><a href="/1.2.0/monitoring/large_state_tuning.html">Debugging and Tuning Checkpoints and Large State</a></li>
    
  

  
    

    
      
    

    
    
    

    

    
    
<li><a href="/1.2.0/monitoring/debugging_event_time.html">Debugging Windows & Event Time</a></li>
    
  

  
    

    
      
    

    
    
    

    

    
    
<li><a href="/1.2.0/monitoring/debugging_classloading.html">Debugging Classloading</a></li>
    
  

  
    

    
      
    

    
    
    

    

    
    
<li><a href="/1.2.0/monitoring/application_profiling.html">Application Profiling</a></li>
    
  

  
    
      
      
</li></ul></div>
      
      
    
  

  
    

    
      
    

    
    
    

    <hr class="section-break"></hr>

    
    
      
      
        
        
<li><a href="#collapse-133" data-toggle="collapse"><i class="fa fa-book title dessert" aria-hidden="true"></i> 内部原理 <i class="fa fa-caret-down pull-right" aria-hidden="true" style="padding-top: 4px"></i></a><div class="collapse" id="collapse-133"><ul>
  
        
        
        

        
        
      
    
  

  
    

    
      
    

    
    
    

    

    
    
<li><a href="/1.2.0/internals/components.html">Component Stack</a></li>
    
  

  
    

    
      
    

    
    
    

    

    
    
<li><a href="/1.2.0/internals/stream_checkpointing.html">Fault Tolerance for Data Streaming</a></li>
    
  

  
    

    
      
    

    
    
    

    

    
    
<li><a href="/1.2.0/internals/job_scheduling.html">Jobs and Scheduling</a></li>
    
  

  
    

    
      
    

    
    
    

    

    
    
<li><a href="/1.2.0/internals/task_lifecycle.html">Task Lifecycle</a></li>
    
  

  
    

    
      
    

    
    
    

    

    
    
<li><a href="/1.2.0/internals/filesystems.html">File Systems</a></li>
    
  

  
    
      
      
</li></ul></div>
      
      
    
  

  
    

    
      
    

    
    
    

    <hr class="section-break"></hr>

    
    
<li><a href="/1.2.0/about/index.html"><i class="fa fa-fire title hot" aria-hidden="true"></i> 参与贡献</a></li>
    
  

  
    
      
  <li class="divider"></li>
  <li><a href="http://flink-china.org"><i class="fa fa-external-link title" aria-hidden="true"></i> 项目页面</a></li>
</ul>

<div class="sidenav-search-box">
  <form class="navbar-form" role="search" action="/1.2.0/search-results.html">
    <div class="form-group">
      <input type="text" class="form-control" size="16px" name="q" placeholder="搜索文档">
    </div>
    <button type="submit" class="btn btn-default">搜索</button>
  </form>
</div>

<div class="sidenav-versions">
  <div class="dropdown">
    <button class="btn btn-default dropdown-toggle" type="button" data-toggle="dropdown">选择文档版本
    <span class="caret"></span></button>
    <ul class="dropdown-menu">
      
      <li><a href="http://doc.flink-china.org/1.1.0/">v1.1</a></li>
      
    </ul>
  </div>
</div>

        </div>
        <div class="col-lg-9 content">
          

          





  
  
    
    
      
    
  

  
  
    
    
      
    
  

  
  
    
    
      



<ol class="breadcrumb">

  
  
    <li><i class="fa fa-code title maindish" aria-hidden="true"></i> 应用开发</li>
  

  
  
    <li><a href="/1.2.0/dev/batch/index.html">批 (DataSet API)</a></li>
  

  
  
    <li class="active">Hadoop Compatibility</li>
  

</ol>

<h1>Hadoop Compatibility <span class="beta">Beta</span></h1>



<p>Flink兼容Apache Hadoop MapReduce的接口，因此可以使用面向MapReduce的代码。</p>

<p>你可以:</p>

<ul>
  <li>Flink中使用Hadoop <code>Writable</code> <a href="index.html#data-types">数据类型（Data type）</a>.</li>
  <li>使用Hadoop <code>InputFormat</code> 作为<a href="index.html#data-sources">数据源（DataSource）</a>.</li>
  <li>使用Hadoop <code>OutputFormat</code> 作为 <a href="index.html#data-sinks">数据落地（DataSink）</a>.</li>
  <li>使用Hadoop <code>Mapper</code> 作为 <a href="dataset_transformations.html#flatmap">FlatMapFunction</a>.</li>
  <li>使用Hadoop <code>Reducer</code> 作为 <a href="dataset_transformations.html#groupreduce-on-grouped-dataset">GroupReduceFunction</a>.</li>
</ul>

<p>这篇文档展示如何在Flink中使用现存的Hadoop MapReduce代码。可以参考
<a href="/1.2.0/dev/batch/connectors.html">连接其他系统</a> 来了解如何从Hadoop支持的文件系统中读取数据。</p>

<ul id="markdown-toc">
  <li><a href="#section" id="markdown-toc-section">项目配置</a></li>
  <li><a href="#hadoop" id="markdown-toc-hadoop">使用Hadoop数据类型</a></li>
  <li><a href="#hadoop-1" id="markdown-toc-hadoop-1">使用Hadoop输入格式</a></li>
  <li><a href="#hadoop-2" id="markdown-toc-hadoop-2">使用Hadoop输出格式</a></li>
  <li><a href="#hadoop-mappersreducers" id="markdown-toc-hadoop-mappersreducers">使用Hadoop Mappers和Reducers</a></li>
  <li><a href="#hadoop-wordcount" id="markdown-toc-hadoop-wordcount">完整Hadoop WordCount示例</a></li>
</ul>

<h3 id="section">项目配置</h3>

<p>支持Hadoop的输入输出（input／output）格式是<code>flink-java</code>和<code>flink-scala</code>的maven模块的一部分，这两部分是在编写Flink任务时经常需要用到的。 <code>mapred</code>和<code>mapreduce</code> 的api代码分别在<code>org.apache.flink.api.java.hadoop</code>和<code>org.apache.flink.api.scala.hadoop</code>以及一个额外的子包中。</p>

<p>对Hadoop MapReduce的支持是在<code>flink-hadoop-compatibility</code>的maven模块中。代码具体在<code>org.apache.flink.hadoopcompatibility</code>包中。</p>

<p>如果想要重复使用<code>Mappers and Reducers</code>， 需要在maven中的pom.xml中添加下面依赖：</p>

<div class="highlight"><pre><code class="language-xml"><span class="nt">&lt;dependency&gt;</span>
	<span class="nt">&lt;groupId&gt;</span>org.apache.flink<span class="nt">&lt;/groupId&gt;</span>
	<span class="nt">&lt;artifactId&gt;</span>flink-hadoop-compatibility_2.10<span class="nt">&lt;/artifactId&gt;</span>
	<span class="nt">&lt;version&gt;</span>1.2<span class="nt">&lt;/version&gt;</span>
<span class="nt">&lt;/dependency&gt;</span></code></pre></div>

<h3 id="hadoop">使用Hadoop数据类型</h3>

<p>Flink支持所有的Hadoop <code>Writable</code> 和 <code>WritableComparable</code> 数据类型, 不用额外添加Hadoop Compatibility 依赖。 可以参考<a href="index.html#data-types">Programming Guide</a>了解如何使用Hadoop数据类型（Hadoop data type）。</p>

<h3 id="hadoop-1">使用Hadoop输入格式</h3>

<p>可以使用Hadoop输入格式来创建数据源，具体是调用 ExecutionEnvironment 的 readHadoopFile 或 createHadoopInput方法。 前者用于来自FileInputFormat的输入格式， 后者用于普通的输入格式。</p>

<p>创建的数据集包含的是一个“键-值”2元组，“值”是从Hadoop输入格式获得的数值。</p>

<p>下面的例子介绍如何使用Hadoop的 <code>TextInputFormat</code>。</p>

<div class="codetabs">
  <div data-lang="java">

    <div class="highlight"><pre><code class="language-java"><span class="n">ExecutionEnvironment</span> <span class="n">env</span> <span class="o">=</span> <span class="n">ExecutionEnvironment</span><span class="o">.</span><span class="na">getExecutionEnvironment</span><span class="o">();</span>

<span class="n">DataSet</span><span class="o">&lt;</span><span class="n">Tuple2</span><span class="o">&lt;</span><span class="n">LongWritable</span><span class="o">,</span> <span class="n">Text</span><span class="o">&gt;&gt;</span> <span class="n">input</span> <span class="o">=</span>
    <span class="n">env</span><span class="o">.</span><span class="na">readHadoopFile</span><span class="o">(</span><span class="k">new</span> <span class="nf">TextInputFormat</span><span class="o">(),</span> <span class="n">LongWritable</span><span class="o">.</span><span class="na">class</span><span class="o">,</span> <span class="n">Text</span><span class="o">.</span><span class="na">class</span><span class="o">,</span> <span class="n">textPath</span><span class="o">);</span>

<span class="c1">// Do something with the data.</span>
<span class="o">[...]</span></code></pre></div>

  </div>
  <div data-lang="scala">

    <div class="highlight"><pre><code class="language-scala"><span class="k">val</span> <span class="n">env</span> <span class="k">=</span> <span class="nc">ExecutionEnvironment</span><span class="o">.</span><span class="n">getExecutionEnvironment</span>

<span class="k">val</span> <span class="n">input</span><span class="k">:</span> <span class="kt">DataSet</span><span class="o">[(</span><span class="kt">LongWritable</span>, <span class="kt">Text</span><span class="o">)]</span> <span class="k">=</span>
  <span class="n">env</span><span class="o">.</span><span class="n">readHadoopFile</span><span class="o">(</span><span class="k">new</span> <span class="nc">TextInputFormat</span><span class="o">,</span> <span class="n">classOf</span><span class="o">[</span><span class="kt">LongWritable</span><span class="o">],</span> <span class="n">classOf</span><span class="o">[</span><span class="kt">Text</span><span class="o">],</span> <span class="n">textPath</span><span class="o">)</span>

<span class="c1">// Do something with the data.</span>
<span class="o">[</span><span class="kt">...</span><span class="o">]</span></code></pre></div>

  </div>

</div>

<h3 id="hadoop-2">使用Hadoop输出格式</h3>

<p>Flink提供兼容Hadoop输出格式（Hadoop OutputFormat）的封装。支持任何实现<code>org.apache.hadoop.mapred.OutputFormat</code>接口或者继承<code>org.apache.hadoop.mapreduce.OutputFormat</code>的类。输出格式的封装需要的输入是“键值对”形式。他们将会交给Hadoop输出格式处理。</p>

<p>下面的例子介绍如何使用Hadoop的 <code>TextOutputFormat</code>。</p>

<div class="codetabs">
  <div data-lang="java">

    <div class="highlight"><pre><code class="language-java"><span class="c1">// 获取所需数据</span>
<span class="n">DataSet</span><span class="o">&lt;</span><span class="n">Tuple2</span><span class="o">&lt;</span><span class="n">Text</span><span class="o">,</span> <span class="n">IntWritable</span><span class="o">&gt;&gt;</span> <span class="n">hadoopResult</span> <span class="o">=</span> <span class="o">[...]</span>

<span class="c1">// 创建和初始化Hadoop TextOutputFormat.</span>
<span class="n">HadoopOutputFormat</span><span class="o">&lt;</span><span class="n">Text</span><span class="o">,</span> <span class="n">IntWritable</span><span class="o">&gt;</span> <span class="n">hadoopOF</span> <span class="o">=</span>
  <span class="k">new</span> <span class="n">HadoopOutputFormat</span><span class="o">&lt;</span><span class="n">Text</span><span class="o">,</span> <span class="n">IntWritable</span><span class="o">&gt;(</span>
    <span class="c1">// 设置Hadoop OutputFormat和特定的job作为初始化参数</span>
    <span class="k">new</span> <span class="n">TextOutputFormat</span><span class="o">&lt;</span><span class="n">Text</span><span class="o">,</span> <span class="n">IntWritable</span><span class="o">&gt;(),</span> <span class="n">job</span>
  <span class="o">);</span>
<span class="n">hadoopOF</span><span class="o">.</span><span class="na">getConfiguration</span><span class="o">().</span><span class="na">set</span><span class="o">(</span><span class="s">&quot;mapreduce.output.textoutputformat.separator&quot;</span><span class="o">,</span> <span class="s">&quot; &quot;</span><span class="o">);</span>
<span class="n">TextOutputFormat</span><span class="o">.</span><span class="na">setOutputPath</span><span class="o">(</span><span class="n">job</span><span class="o">,</span> <span class="k">new</span> <span class="nf">Path</span><span class="o">(</span><span class="n">outputPath</span><span class="o">));</span>

<span class="c1">// 通过Hadoop TextOutputFormat输出结果</span>
<span class="n">hadoopResult</span><span class="o">.</span><span class="na">output</span><span class="o">(</span><span class="n">hadoopOF</span><span class="o">);</span></code></pre></div>

  </div>
  <div data-lang="scala">

    <div class="highlight"><pre><code class="language-scala"><span class="c1">// 获取所需数据</span>
<span class="k">val</span> <span class="n">hadoopResult</span><span class="k">:</span> <span class="kt">DataSet</span><span class="o">[(</span><span class="kt">Text</span>, <span class="kt">IntWritable</span><span class="o">)]</span> <span class="k">=</span> <span class="o">[</span><span class="kt">...</span><span class="o">]</span>

<span class="k">val</span> <span class="n">hadoopOF</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">HadoopOutputFormat</span><span class="o">[</span><span class="kt">Text</span>,<span class="kt">IntWritable</span><span class="o">](</span>
  <span class="k">new</span> <span class="nc">TextOutputFormat</span><span class="o">[</span><span class="kt">Text</span>, <span class="kt">IntWritable</span><span class="o">],</span>
  <span class="k">new</span> <span class="nc">JobConf</span><span class="o">)</span>

<span class="n">hadoopOF</span><span class="o">.</span><span class="n">getJobConf</span><span class="o">.</span><span class="n">set</span><span class="o">(</span><span class="s">&quot;mapred.textoutputformat.separator&quot;</span><span class="o">,</span> <span class="s">&quot; &quot;</span><span class="o">)</span>
<span class="nc">FileOutputFormat</span><span class="o">.</span><span class="n">setOutputPath</span><span class="o">(</span><span class="n">hadoopOF</span><span class="o">.</span><span class="n">getJobConf</span><span class="o">,</span> <span class="k">new</span> <span class="nc">Path</span><span class="o">(</span><span class="n">resultPath</span><span class="o">))</span>

<span class="n">hadoopResult</span><span class="o">.</span><span class="n">output</span><span class="o">(</span><span class="n">hadoopOF</span><span class="o">)</span></code></pre></div>

  </div>

</div>

<h3 id="hadoop-mappersreducers">使用Hadoop Mappers和Reducers</h3>

<p><code>Hadoop Mappers</code> 语法上等价于Flink的<code>FlatMapFunctions</code>，<code>Hadoop Reducers</code>语法上等价于Flink的<code>GroupReduceFunctions</code>。 Flink同样封装了<code>Hadoop MapReduce</code>的<code>Mapper and Reducer</code>接口的实现。 用户可以在Flink程序中复用Hadoop的<code>Mappers and Reducers</code>。 这时，仅仅<code>org.apache.hadoop.mapred</code>的Mapper and Reducer接口被支持。</p>

<p>The wrappers take a <code>DataSet&lt;Tuple2&lt;KEYIN,VALUEIN&gt;&gt;</code> as input and produce a <code>DataSet&lt;Tuple2&lt;KEYOUT,VALUEOUT&gt;&gt;</code> as output where <code>KEYIN</code> and <code>KEYOUT</code> are the keys and <code>VALUEIN</code> and <code>VALUEOUT</code> are the values of the Hadoop key-value pairs that are processed by the Hadoop functions. For Reducers, Flink offers a wrapper for a GroupReduceFunction with (<code>HadoopReduceCombineFunction</code>) and without a Combiner (<code>HadoopReduceFunction</code>). The wrappers accept an optional <code>JobConf</code> object to configure the Hadoop Mapper or Reducer.</p>

<p>封装函数用<code>DataSet&lt;Tuple2&lt;KEYIN,VALUEIN&gt;&gt;</code>作为输入， 产生<code>DataSet&lt;Tuple2&lt;KEYOUT,VALUEOUT&gt;&gt;</code>作为输出， 其中<code>KEYIN</code>和<code>KEYOUT</code>是“键” ，<code>VALUEIN</code> 和<code>VALUEOUT</code> 是“值”，它们是Hadoop函数处理的键值对。 对于Reducers，Flink将GroupReduceFunction封装成<code>HadoopReduceCombineFunction</code>，但没有Combiner(<code>HadoopReduceFunction</code>)。 封装函数接收可选的<code>JobConf</code>对象来配置Hadoop的Mapper or Reducer。</p>

<p>Flink的方法封装有</p>

<ul>
  <li><code>org.apache.flink.hadoopcompatibility.mapred.HadoopMapFunction</code>,</li>
  <li><code>org.apache.flink.hadoopcompatibility.mapred.HadoopReduceFunction</code>, and</li>
  <li><code>org.apache.flink.hadoopcompatibility.mapred.HadoopReduceCombineFunction</code>.
他们可以被用于<a href="dataset_transformations.html#flatmap">FlatMapFunctions</a>或<a href="dataset_transformations.html#groupreduce-on-grouped-dataset">GroupReduceFunctions</a>.</li>
</ul>

<p>下面的例子介绍如何使用Hadoop的<code>Mapper</code>和<code>Reducer</code> 。</p>

<div class="highlight"><pre><code class="language-java"><span class="c1">// 获取待处理数据</span>
<span class="n">DataSet</span><span class="o">&lt;</span><span class="n">Tuple2</span><span class="o">&lt;</span><span class="n">Text</span><span class="o">,</span> <span class="n">LongWritable</span><span class="o">&gt;&gt;</span> <span class="n">text</span> <span class="o">=</span> <span class="o">[...]</span>

<span class="n">DataSet</span><span class="o">&lt;</span><span class="n">Tuple2</span><span class="o">&lt;</span><span class="n">Text</span><span class="o">,</span> <span class="n">LongWritable</span><span class="o">&gt;&gt;</span> <span class="n">result</span> <span class="o">=</span> <span class="n">text</span>
  <span class="c1">// 使用Hadoop Mapper (Tokenizer)作为Map函数</span>
  <span class="o">.</span><span class="na">flatMap</span><span class="o">(</span><span class="k">new</span> <span class="n">HadoopMapFunction</span><span class="o">&lt;</span><span class="n">LongWritable</span><span class="o">,</span> <span class="n">Text</span><span class="o">,</span> <span class="n">Text</span><span class="o">,</span> <span class="n">LongWritable</span><span class="o">&gt;(</span>
    <span class="k">new</span> <span class="nf">Tokenizer</span><span class="o">()</span>
  <span class="o">))</span>
  <span class="o">.</span><span class="na">groupBy</span><span class="o">(</span><span class="mi">0</span><span class="o">)</span>
  <span class="c1">// 使用Hadoop Reducer (Counter)作为Reduce函数</span>
  <span class="o">.</span><span class="na">reduceGroup</span><span class="o">(</span><span class="k">new</span> <span class="n">HadoopReduceCombineFunction</span><span class="o">&lt;</span><span class="n">Text</span><span class="o">,</span> <span class="n">LongWritable</span><span class="o">,</span> <span class="n">Text</span><span class="o">,</span> <span class="n">LongWritable</span><span class="o">&gt;(</span>
    <span class="k">new</span> <span class="nf">Counter</span><span class="o">(),</span> <span class="k">new</span> <span class="nf">Counter</span><span class="o">()</span>
  <span class="o">));</span></code></pre></div>

<p><strong>需要注意:</strong> Reducer封装处理由Flink中的<a href="dataset_transformations.html#transformations-on-grouped-dataset">groupBy()</a>定义的groups。 它并不考虑任何在JobConf定义的自定义的分区器(partitioners), 排序（sort）或分组（grouping）的比较器。</p>

<h3 id="hadoop-wordcount">完整Hadoop WordCount示例</h3>

<p>下面给出一个完整的使用Hadoop 数据类型， InputFormat/OutputFormat/Mapper/Reducer的示例。</p>

<div class="highlight"><pre><code class="language-java"><span class="n">ExecutionEnvironment</span> <span class="n">env</span> <span class="o">=</span> <span class="n">ExecutionEnvironment</span><span class="o">.</span><span class="na">getExecutionEnvironment</span><span class="o">();</span>

<span class="c1">// 创建和初始化Hadoop TextInputFormat.</span>
<span class="n">Job</span> <span class="n">job</span> <span class="o">=</span> <span class="n">Job</span><span class="o">.</span><span class="na">getInstance</span><span class="o">();</span>
<span class="n">HadoopInputFormat</span><span class="o">&lt;</span><span class="n">LongWritable</span><span class="o">,</span> <span class="n">Text</span><span class="o">&gt;</span> <span class="n">hadoopIF</span> <span class="o">=</span>
  <span class="k">new</span> <span class="n">HadoopInputFormat</span><span class="o">&lt;</span><span class="n">LongWritable</span><span class="o">,</span> <span class="n">Text</span><span class="o">&gt;(</span>
    <span class="k">new</span> <span class="nf">TextInputFormat</span><span class="o">(),</span> <span class="n">LongWritable</span><span class="o">.</span><span class="na">class</span><span class="o">,</span> <span class="n">Text</span><span class="o">.</span><span class="na">class</span><span class="o">,</span> <span class="n">job</span>
  <span class="o">);</span>
<span class="n">TextInputFormat</span><span class="o">.</span><span class="na">addInputPath</span><span class="o">(</span><span class="n">job</span><span class="o">,</span> <span class="k">new</span> <span class="nf">Path</span><span class="o">(</span><span class="n">inputPath</span><span class="o">));</span>

<span class="c1">// 从Hadoop TextInputFormat读取数据.</span>
<span class="n">DataSet</span><span class="o">&lt;</span><span class="n">Tuple2</span><span class="o">&lt;</span><span class="n">LongWritable</span><span class="o">,</span> <span class="n">Text</span><span class="o">&gt;&gt;</span> <span class="n">text</span> <span class="o">=</span> <span class="n">env</span><span class="o">.</span><span class="na">createInput</span><span class="o">(</span><span class="n">hadoopIF</span><span class="o">);</span>

<span class="n">DataSet</span><span class="o">&lt;</span><span class="n">Tuple2</span><span class="o">&lt;</span><span class="n">Text</span><span class="o">,</span> <span class="n">LongWritable</span><span class="o">&gt;&gt;</span> <span class="n">result</span> <span class="o">=</span> <span class="n">text</span>
  <span class="c1">// 使用Hadoop Mapper (Tokenizer)作为Map函数</span>
  <span class="o">.</span><span class="na">flatMap</span><span class="o">(</span><span class="k">new</span> <span class="n">HadoopMapFunction</span><span class="o">&lt;</span><span class="n">LongWritable</span><span class="o">,</span> <span class="n">Text</span><span class="o">,</span> <span class="n">Text</span><span class="o">,</span> <span class="n">LongWritable</span><span class="o">&gt;(</span>
    <span class="k">new</span> <span class="nf">Tokenizer</span><span class="o">()</span>
  <span class="o">))</span>
  <span class="o">.</span><span class="na">groupBy</span><span class="o">(</span><span class="mi">0</span><span class="o">)</span>
  <span class="c1">// 使用Hadoop Reducer (Counter)作为Reduce函数</span>
  <span class="o">.</span><span class="na">reduceGroup</span><span class="o">(</span><span class="k">new</span> <span class="n">HadoopReduceCombineFunction</span><span class="o">&lt;</span><span class="n">Text</span><span class="o">,</span> <span class="n">LongWritable</span><span class="o">,</span> <span class="n">Text</span><span class="o">,</span> <span class="n">LongWritable</span><span class="o">&gt;(</span>
    <span class="k">new</span> <span class="nf">Counter</span><span class="o">(),</span> <span class="k">new</span> <span class="nf">Counter</span><span class="o">()</span>
  <span class="o">));</span>

<span class="c1">// 创建和初始化Hadoop TextOutputFormat.</span>
<span class="n">HadoopOutputFormat</span><span class="o">&lt;</span><span class="n">Text</span><span class="o">,</span> <span class="n">IntWritable</span><span class="o">&gt;</span> <span class="n">hadoopOF</span> <span class="o">=</span>
  <span class="k">new</span> <span class="n">HadoopOutputFormat</span><span class="o">&lt;</span><span class="n">Text</span><span class="o">,</span> <span class="n">IntWritable</span><span class="o">&gt;(</span>
    <span class="k">new</span> <span class="n">TextOutputFormat</span><span class="o">&lt;</span><span class="n">Text</span><span class="o">,</span> <span class="n">IntWritable</span><span class="o">&gt;(),</span> <span class="n">job</span>
  <span class="o">);</span>
<span class="n">hadoopOF</span><span class="o">.</span><span class="na">getConfiguration</span><span class="o">().</span><span class="na">set</span><span class="o">(</span><span class="s">&quot;mapreduce.output.textoutputformat.separator&quot;</span><span class="o">,</span> <span class="s">&quot; &quot;</span><span class="o">);</span>
<span class="n">TextOutputFormat</span><span class="o">.</span><span class="na">setOutputPath</span><span class="o">(</span><span class="n">job</span><span class="o">,</span> <span class="k">new</span> <span class="nf">Path</span><span class="o">(</span><span class="n">outputPath</span><span class="o">));</span>

<span class="c1">// 使用Hadoop TextOutputFormat输出结果.</span>
<span class="n">result</span><span class="o">.</span><span class="na">output</span><span class="o">(</span><span class="n">hadoopOF</span><span class="o">);</span>

<span class="c1">// 执行程序</span>
<span class="n">env</span><span class="o">.</span><span class="na">execute</span><span class="o">(</span><span class="s">&quot;Hadoop WordCount&quot;</span><span class="o">);</span></code></pre></div>


 <div class="footer">
  发现错误？想参与编辑？
  <a href="https://github.com/flink-china/flink-china-doc/edit/1.2.0/dev/batch/hadoop_compatibility.md" target="_blank">
    在 Github 上编辑此页！
  </a>
</div>

        </div>
      </div>
    </div><!-- /.container -->

    <!-- jQuery (necessary for Bootstrap's JavaScript plugins) -->
    <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.11.2/jquery.min.js"></script>
    <!-- Include all compiled plugins (below), or include individual files as needed -->
    <script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.4/js/bootstrap.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/anchor-js/3.1.0/anchor.min.js"></script>
    <script src="/1.2.0/page/js/flink.js"></script>

   <!-- Baidu Analytics -->
    <script>
      var _hmt = _hmt || [];
      (function() {
        var hm = document.createElement("script");
        hm.src = "//hm.baidu.com/hm.js?835985ad7943d8c24bc3c1f155b7d4a2";
        var s = document.getElementsByTagName("script")[0]; 
        s.parentNode.insertBefore(hm, s);
      })();
    </script>

    <!-- Disqus -->
    
  </body>
</html>
